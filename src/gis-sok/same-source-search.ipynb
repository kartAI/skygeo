{
 "cells": [
  {
   "cell_type": "code",
   "id": "97a8a5043ed09d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T12:34:59.753913Z",
     "start_time": "2025-11-12T12:34:59.364833Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "import duckdb\n",
    "from shapely import from_wkb"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgeopandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgpd\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mduckdb\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mshapely\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m from_wkb\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'geopandas'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc7543935618c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DuckDB connection and Azure access\n",
    "con = duckdb.connect(\":memory:\")\n",
    "con.execute(\"INSTALL spatial; LOAD spatial;\")\n",
    "con.execute(\"INSTALL azure; LOAD azure;\")\n",
    "\n",
    "# Create Azure secret for public access\n",
    "con.execute(\"\"\"\n",
    "CREATE SECRET secret (\n",
    "    TYPE azure,\n",
    "    PROVIDER config,\n",
    "    ACCOUNT_NAME 'doppablobstorage'\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Use curl transport for Azure requests\n",
    "con.execute(\"SET azure_transport_option_type = curl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a82f7942b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_1 = \"az://raw/release/2025-10-27.19/dataset=osm/theme=buildings/region=*/*.parquet\"\n",
    "release_2 = \"az://raw/release/2025-11-12.0/dataset=osm/theme=buildings/region=*/*.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9d14c746a7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_release_1 = con.execute(f\"SELECT count(*) AS count FROM '{release_1}'\").fetchone()[0]\n",
    "count_release_2 = con.execute(f\"SELECT count(*) AS count FROM '{release_2}'\").fetchone()[0]\n",
    "print(\"Number of rows release 1:\", count_release_1)\n",
    "print(\"Number of rows release 2:\", count_release_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c64c3fa968d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare geometries directly (not hashes)\n",
    "query_geo = f\"\"\"\n",
    "WITH old AS (\n",
    "    SELECT id, ST_Normalize(geometry) AS geom\n",
    "    FROM read_parquet('{release_1}')\n",
    "),\n",
    "new AS (\n",
    "    SELECT id, ST_Normalize(geometry) AS geom\n",
    "    FROM read_parquet('{release_2}')\n",
    ")\n",
    "SELECT\n",
    "    COALESCE(n.id, o.id) AS id,\n",
    "    n.id AS new_id,\n",
    "    o.id AS old_id\n",
    "FROM new n\n",
    "FULL OUTER JOIN old o ON n.id = o.id\n",
    "WHERE NOT ST_Equals(n.geom, o.geom);\n",
    "\"\"\"\n",
    "\n",
    "df_geo = con.execute(query_geo).df_geo()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compare geometries by canonical hash (faster, less precise)\n",
    "query_hash = f\"\"\"\n",
    "WITH old AS (\n",
    "    SELECT id, md5(ST_AsWKB(ST_Normalize(geometry))) AS geom_hash\n",
    "    FROM read_parquet('{release_1}')\n",
    "),\n",
    "new AS (\n",
    "    SELECT id, md5(ST_AsWKB(ST_Normalize(geometry))) AS geom_hash\n",
    "    FROM read_parquet('{release_2}')\n",
    ")\n",
    "SELECT\n",
    "    COALESCE(n.id, o.id) AS id,\n",
    "    n.id AS new_id,\n",
    "    o.id AS old_id\n",
    "FROM new n\n",
    "FULL OUTER JOIN old o ON n.id = o.id\n",
    "WHERE n.geom_hash IS DISTINCT FROM o.geom_hash;\n",
    "\"\"\"\n",
    "df_hash = con.execute(query_hash).df_geo()"
   ],
   "id": "21b3141685098701"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(df_geo.shape)\n",
    "print(df_hash.shape)"
   ],
   "id": "a26976dfbf820589"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759d754b7c1ec16",
   "metadata": {},
   "outputs": [],
   "source": "changed_ids = df_geo[\"id\"].to_numpy()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579c6331fce28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch changed geometries for release 1\n",
    "query = f\"\"\"\n",
    "SELECT id, ST_AsWKB(geometry) AS geometry\n",
    "FROM '{release_1}'\n",
    "WHERE id IN ({','.join(map(str, changed_ids))})\n",
    "ORDER BY id;\n",
    "\"\"\"\n",
    "release_1_diff = con.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496d4c1a2c09831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch changed geometries for release 2\n",
    "query = f\"\"\"\n",
    "SELECT id, ST_AsWKB(geometry) AS geometry\n",
    "FROM '{release_2}'\n",
    "WHERE id IN ({','.join(map(str, changed_ids))})\n",
    "ORDER BY id;\n",
    "\"\"\"\n",
    "release_2_diff = con.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a421b46c16402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure geometry columns are proper byte arrays\n",
    "release_1_diff['geometry'] = release_1_diff['geometry'].apply(lambda g: bytes(g) if isinstance(g, (memoryview, bytearray)) else g)\n",
    "release_2_diff['geometry'] = release_2_diff['geometry'].apply(lambda g: bytes(g) if isinstance(g, (memoryview, bytearray)) else g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2106784ca05750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert WKB to shapely geometries\n",
    "release_1_diff['geometry'] = release_1_diff['geometry'].apply(from_wkb)\n",
    "release_2_diff['geometry'] = release_2_diff['geometry'].apply(from_wkb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65fc7962a1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoDataFrames\n",
    "release_1_gdf = gpd.GeoDataFrame(release_1_diff, geometry='geometry', crs='EPSG:4326')\n",
    "release_2_gdf = gpd.GeoDataFrame(release_2_diff, geometry='geometry', crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1f02c38809c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save to Parquet\n",
    "# release_1_gdf.to_parquet('release_1.parquet', schema_version='1.1.0')\n",
    "# release_2_gdf.to_parquet('release_2.parquet', schema_version='1.1.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
