{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af740cc",
   "metadata": {},
   "source": [
    "# GeoNorge CSW til STAC Catalog – Eksperiment\n",
    "\n",
    "Dette prosjektet demonstrerer hvordan metadatakatalogen fra GeoNorge (CSW) kan konverteres til en STAC-katalog, både som JSON og GeoParquet. Målet er å gjøre norske geodata enklere tilgjengelig og mer brukervennlig for både mennesker og maskiner.\n",
    "\n",
    "## Teknisk gjennomgang\n",
    "\n",
    "Notebooken `iso2stac_experiment.ipynb` viser hele prosessen:\n",
    "- Henter metadata fra GeoNorge CSW med OWSLib\n",
    "- Mapper metadata til STAC-format med dynamisk utvidelse av egenskaper\n",
    "- Oppretter STAC-katalog og collections basert på publisher\n",
    "- Eksporterer katalogen til både JSON og GeoParquet\n",
    "- Viser hvordan resultatene kan visualiseres og analyseres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5920aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install required libraries\n",
    "%pip install OWSLib pystac stac-geoparquet pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10077142",
   "metadata": {},
   "source": [
    "Setup csw url and output path\n",
    "\n",
    "Connect to csw using owslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b9d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to https://www.geonorge.no/geonetworktest/srv/eng/csw...\n",
      "Connected to: Geonetwork - Test\n",
      "Service Type: CSW\n",
      "Service Version: 2.0.2\n",
      "Abstract: None\n"
     ]
    }
   ],
   "source": [
    "from owslib.csw import CatalogueServiceWeb\n",
    "from pystac import Catalog, Collection, Item, Asset, Extent, SpatialExtent, TemporalExtent, CatalogType\n",
    "from datetime import datetime, timezone\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "CSW_URL = 'https://www.geonorge.no/geonetworktest/srv/eng/csw'\n",
    "\n",
    "### Windows file paths - change to linux style if needed\n",
    "STAC_DIR = '.\\\\output\\\\stac_output_dynamic'\n",
    "\n",
    "# Connect to CSW\n",
    "print(f\"Connecting to {CSW_URL}...\")\n",
    "csw = CatalogueServiceWeb(CSW_URL)\n",
    "print(f\"Connected to: {csw.identification.title}\")\n",
    "print(f\"Service Type: {csw.identification.type}\")\n",
    "print(f\"Service Version: {csw.identification.version}\")\n",
    "print(f\"Abstract: {csw.identification.abstract}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1103d",
   "metadata": {},
   "source": [
    "### Helper functions. \n",
    "Defines helper functions for bbox and type determination. Type determination defines the collection splits for the actual STAC catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a93e6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def get_bbox(record):\n",
    "    \"\"\"Extract bbox from CSW record, handling CRS and axis order.\"\"\"\n",
    "    import xml.etree.ElementTree as ET\n",
    "    \n",
    "    # Default global bbox\n",
    "    default_bbox = [-180.0, -90.0, 180.0, 90.0]\n",
    "    \n",
    "    try:\n",
    "        # 1. Try to parse raw XML for ows:BoundingBox to handle axis order (Lat/Lon vs Lon/Lat)\n",
    "        if hasattr(record, 'xml') and record.xml:\n",
    "            # Parse XML\n",
    "            root = ET.fromstring(record.xml)\n",
    "            namespaces = {\n",
    "                'ows': 'http://www.opengis.net/ows',\n",
    "                'csw': 'http://www.opengis.net/cat/csw/2.0.2'\n",
    "            }\n",
    "            \n",
    "            bbox_elem = root.find('.//ows:BoundingBox', namespaces)\n",
    "            if bbox_elem is not None:\n",
    "                lower_corner = bbox_elem.find('ows:LowerCorner', namespaces)\n",
    "                upper_corner = bbox_elem.find('ows:UpperCorner', namespaces)\n",
    "                \n",
    "                if lower_corner is not None and upper_corner is not None:\n",
    "                    lc_coords = [float(x) for x in lower_corner.text.split()]\n",
    "                    uc_coords = [float(x) for x in upper_corner.text.split()]\n",
    "                    \n",
    "                    crs = bbox_elem.get('crs', '')\n",
    "                    \n",
    "                    # Handle Axis Order\n",
    "                    # EPSG:4326 is typically Lat/Lon in OGC services\n",
    "                    # Heuristic: If first coordinate is > 45 (likely Lat for Norway) and second is < 45 (Lon)\n",
    "                    if '4326' in crs or (lc_coords[0] > lc_coords[1] and lc_coords[0] > 30):\n",
    "                        # Swap from Lat/Lon to Lon/Lat (STAC uses Lon/Lat)\n",
    "                        miny, minx = lc_coords[0], lc_coords[1]\n",
    "                        maxy, maxx = uc_coords[0], uc_coords[1]\n",
    "                    else:\n",
    "                        minx, miny = lc_coords[0], lc_coords[1]\n",
    "                        maxx, maxy = uc_coords[0], uc_coords[1]\n",
    "                        \n",
    "                    return [minx, miny, maxx, maxy]\n",
    "\n",
    "        # 2. Fallback to OWSLib parsed bbox\n",
    "        if record.bbox:\n",
    "            # OWSLib usually returns (minx, miny, maxx, maxy)\n",
    "            # But verify if it looks swapped\n",
    "            b = [float(record.bbox.minx), float(record.bbox.miny), float(record.bbox.maxx), float(record.bbox.maxy)]\n",
    "            # Apply same heuristic\n",
    "            if b[0] > b[1] and b[0] > 30:\n",
    "                 return [b[1], b[0], b[3], b[2]]\n",
    "            return b\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not parse bbox for {record.identifier}: {e}\")\n",
    "\n",
    "    return default_bbox\n",
    "\n",
    "## THEMATIC COLLECTION DETERMINATION BASED ON PUBLISHER\n",
    "## Could be extended to use keywords or other metadata\n",
    "## this is essential for the structure of the STAC catalog\n",
    "def determine_type(record):\n",
    "    \"\"\"Determine collection based on publisher.\"\"\"\n",
    "    publisher = 'unknown-publisher'\n",
    "    \n",
    "    # OWSLib maps dc:publisher to record.publisher\n",
    "    if hasattr(record, 'publisher') and record.publisher:\n",
    "        if isinstance(record.publisher, list):\n",
    "             if len(record.publisher) > 0:\n",
    "                 publisher = record.publisher[0]\n",
    "        else:\n",
    "            publisher = record.publisher\n",
    "            \n",
    "    # Sanitize for use in ID\n",
    "    clean_publisher = re.sub(r'[^a-zA-Z0-9-_]', '_', str(publisher).lower())\n",
    "    clean_publisher = re.sub(r'_+', '_', clean_publisher).strip('_')\n",
    "    \n",
    "    return clean_publisher if clean_publisher else 'unknown-publisher'\n",
    "\n",
    "## The actual mapping function between CSW record and STAC Item\n",
    "def csw_record_to_stac_item(record):\n",
    "    \"\"\"Convert a single CSW record to a pystac.Item.\"\"\"\n",
    "    # Sanitize ID\n",
    "    item_id = re.sub(r'[^a-zA-Z0-9-_]', '_', record.identifier)\n",
    "    \n",
    "    bbox = get_bbox(record)\n",
    "    \n",
    "    # Create GeoJSON Geometry from BBox\n",
    "    # bbox is [minx, miny, maxx, maxy]\n",
    "    geometry = {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [[\n",
    "            [bbox[0], bbox[1]],\n",
    "            [bbox[2], bbox[1]],\n",
    "            [bbox[2], bbox[3]],\n",
    "            [bbox[0], bbox[3]],\n",
    "            [bbox[0], bbox[1]]\n",
    "        ]]\n",
    "    }\n",
    "    \n",
    "    # Time: Default to now if not found. \n",
    "    # Real implementation should parse record.temporal_extent or modified date.\n",
    "    dt = datetime.now(timezone.utc)\n",
    "    \n",
    "    # Base properties\n",
    "    properties = {\n",
    "        \"title\": record.title,\n",
    "        \"description\": record.abstract,\n",
    "    }\n",
    "    \n",
    "    # Dynamic metadata extraction\n",
    "    # Extract all public attributes from the record object\n",
    "    # We exclude spatial properties (bbox), internal ones (xml), and those already mapped (title, abstract, references)\n",
    "    ignore_attributes = {'bbox', 'xml', 'references', 'uris', 'title', 'abstract'} \n",
    "    \n",
    "    for attr in dir(record):\n",
    "        # Skip private attributes and ignored ones\n",
    "        if attr.startswith('_') or attr in ignore_attributes:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            value = getattr(record, attr)\n",
    "            \n",
    "            # Skip callables (methods)\n",
    "            if callable(value):\n",
    "                continue\n",
    "                \n",
    "            # Skip None or empty lists\n",
    "            if value is None or (isinstance(value, list) and len(value) == 0):\n",
    "                continue\n",
    "                \n",
    "            # Add to properties with csw: prefix to avoid collision and indicate source\n",
    "            properties[f\"csw:{attr}\"] = value\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    item = Item(\n",
    "        id=item_id,\n",
    "        geometry=geometry,\n",
    "        bbox=bbox,\n",
    "        datetime=dt,\n",
    "        properties=properties\n",
    "    )\n",
    "    \n",
    "    # Add Assets (References)\n",
    "    # In OWSLib, record.uris is a list of dicts: [{'protocol': '...', 'name': '...', 'description': '...', 'url': '...'}]\n",
    "    # record.references is a list of dicts: [{'scheme': '...', 'url': '...'}]\n",
    "    # We prefer URIs if available as they have more metadata (protocol/name)\n",
    "    \n",
    "    assets_source = record.uris if hasattr(record, 'uris') and record.uris else record.references\n",
    "    \n",
    "    for i, ref in enumerate(assets_source):\n",
    "        href = ref.get('url')\n",
    "        if not href: continue\n",
    "            \n",
    "        # Extract metadata\n",
    "        protocol = ref.get('protocol', ref.get('scheme', 'unknown')).lower()\n",
    "        name = ref.get('name', f'asset_{i}')\n",
    "        description = ref.get('description', '')\n",
    "        \n",
    "        # Determine roles and media types\n",
    "        roles = []\n",
    "        media_type = None\n",
    "        \n",
    "        if 'image' in protocol or 'jpg' in href or 'png' in href:\n",
    "            roles.append('thumbnail')\n",
    "            if 'jpg' in href: media_type = 'image/jpeg'\n",
    "            if 'png' in href: media_type = 'image/png'\n",
    "        elif 'wms' in protocol:\n",
    "            roles.append('visual')\n",
    "            media_type = 'image/wms'\n",
    "        elif 'wfs' in protocol:\n",
    "            roles.append('data')\n",
    "            media_type = 'application/wfs'\n",
    "        elif 'download' in protocol:\n",
    "            roles.append('data')\n",
    "        else:\n",
    "            roles.append('metadata')\n",
    "\n",
    "        item.add_asset(\n",
    "            key=name if name else f\"asset_{i}\",\n",
    "            asset=Asset(\n",
    "                href=href, \n",
    "                title=name, \n",
    "                description=description,\n",
    "                media_type=media_type,\n",
    "                roles=roles\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d1c59c",
   "metadata": {},
   "source": [
    "### Harvest and build the STAC catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd726d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Harvest and Build Catalog\n",
    "\n",
    "# Create Root Catalog\n",
    "catalog = Catalog(\n",
    "    id=\"geonorge-csw-catalog\",\n",
    "    description=\"STAC Catalog harvested from Geonorge CSW\"\n",
    ")\n",
    "\n",
    "# Collections map to keep track of created collections\n",
    "collections = {}\n",
    "\n",
    "# Paging Configuration\n",
    "start_position = 1\n",
    "max_records = 1000 # Records per request (adjust as needed)\n",
    "sleep_seconds = 1 # Pause between requests to avoid throttling\n",
    "\n",
    "print(\"Starting harvest...\")\n",
    "\n",
    "while True:\n",
    "    print(f\"Fetching records starting at {start_position}...\")\n",
    "    try:\n",
    "        csw.getrecords2(startposition=start_position, maxrecords=max_records, esn='full')\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching records: {e}\")\n",
    "        break\n",
    "    \n",
    "    fetched_count = len(csw.records)\n",
    "    print(f\"  Fetched {fetched_count} records.\")\n",
    "    \n",
    "    if fetched_count == 0:\n",
    "        break\n",
    "    \n",
    "    # Process records\n",
    "    for rec_id, rec in csw.records.items():\n",
    "        try:\n",
    "            # Determine Collection (e.g., by publisher)\n",
    "            ctype = determine_type(rec)\n",
    "            coll_id = f\"collection-{ctype}\"\n",
    "            \n",
    "            if coll_id not in collections:\n",
    "                # Create Collection if not exists\n",
    "                coll = Collection(\n",
    "                    id=coll_id,\n",
    "                    description=f\"Collection for {ctype} datasets\",\n",
    "                    extent=Extent(\n",
    "                        spatial=SpatialExtent([[-180, -90, 180, 90]]),\n",
    "                        temporal=TemporalExtent([[None, None]])\n",
    "                    )\n",
    "                )\n",
    "                collections[coll_id] = coll\n",
    "                catalog.add_child(coll)\n",
    "                \n",
    "            # Create Item\n",
    "            item = csw_record_to_stac_item(rec)\n",
    "            collections[coll_id].add_item(item)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process record {rec_id}: {e}\")\n",
    "\n",
    "    # Check for next page\n",
    "    # nextrecord is 0 if no more records\n",
    "    next_record = csw.results.get('nextrecord', 0)\n",
    "    if next_record == 0 or next_record <= start_position:\n",
    "        break\n",
    "        \n",
    "    start_position = next_record\n",
    "    time.sleep(sleep_seconds)\n",
    "\n",
    "print(f\"Harvest complete. Total collections: {len(collections)}\")\n",
    "\n",
    "# Update Collection Extents based on items\n",
    "print(\"Updating collection spatial and temporal extents...\")\n",
    "for child in catalog.get_children():\n",
    "    if isinstance(child, Collection):\n",
    "        child.update_extent_from_items()\n",
    "\n",
    "# Save\n",
    "print(f\"Saving catalog to {STAC_DIR}...\")\n",
    "os.makedirs(STAC_DIR, exist_ok=True)\n",
    "catalog.normalize_and_save(STAC_DIR, catalog_type=CatalogType.SELF_CONTAINED)\n",
    "print(f\"Saved STAC catalog to {os.path.abspath(STAC_DIR)}\")\n",
    "\n",
    "# List structure\n",
    "print(\"\\nCatalog Structure:\")\n",
    "for child in catalog.get_children():\n",
    "    print(f\" - Collection: {child.id} ({len(list(child.get_items()))} items)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a7a0bd",
   "metadata": {},
   "source": [
    "### Convert STAC to STAC-GeoParquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff601f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items for GeoParquet conversion...\n",
      "Found 9884 items.\n",
      "Writing to .\\geonorge_stac.parquet...\n",
      "Conversion complete: c:\\dev\\skygeo\\src\\iso2stac\\geonorge_stac.parquet\n",
      "Conversion complete: c:\\dev\\skygeo\\src\\iso2stac\\geonorge_stac.parquet\n"
     ]
    }
   ],
   "source": [
    "# Convert STAC catalog to Parquet files for easier querying and analysis\n",
    "\n",
    "import stac_geoparquet\n",
    "import os\n",
    "\n",
    "### Windows style file paths - change to linux style if needed\n",
    "output_dir = '.\\\\output\\\\'\n",
    "\n",
    "# Output file\n",
    "parquet_file = os.path.join(output_dir, \"geonorge_stac.parquet\")\n",
    "\n",
    "# Collect all items\n",
    "print(\"Collecting items for GeoParquet conversion...\")\n",
    "\n",
    "items = list(catalog.get_all_items())\n",
    "print(f\"Found {len(items)} items.\")\n",
    "\n",
    "if items:\n",
    "    print(f\"Writing to {parquet_file}...\")\n",
    "    record_batch_reader = stac_geoparquet.arrow.parse_stac_items_to_arrow(items)\n",
    "    table = record_batch_reader.read_all()\n",
    "    stac_geoparquet.arrow.to_parquet(table, parquet_file)\n",
    "    print(f\"Conversion complete: {os.path.abspath(parquet_file)}\")\n",
    "else:\n",
    "    print(\"No items found in catalog.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
